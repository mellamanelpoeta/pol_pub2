{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carga y preparación de datos\n",
    "# Leemos los archivos CSV\n",
    "math_df = pd.read_csv('wb_pisa_math.csv')\n",
    "reading_df = pd.read_csv('wb_pisa_reading.csv')\n",
    "science_df = pd.read_csv('wb_pisa_science.csv')\n",
    "\n",
    "# Función para transformar datos de formato wide a long\n",
    "def reshape_pisa_data(df, subject):\n",
    "    # Seleccionamos columnas de años y metadata\n",
    "    year_cols = [col for col in df.columns if col.endswith('_Mean')]\n",
    "    years = [int(col.split('_')[0]) for col in year_cols]\n",
    "    \n",
    "    # Creamos id_vars con columnas que no son de años\n",
    "    id_vars = ['Country', 'Treatment', 'Pandemic_Deaths_2020', \n",
    "               'Education_Spending_Percent_GDP', 'GDP_Per_Capita_2018',\n",
    "               'COVID_Death_Percent_Population']\n",
    "    \n",
    "    # Reshape a formato long\n",
    "    df_long = pd.melt(df, \n",
    "                      id_vars=id_vars,\n",
    "                      value_vars=year_cols,\n",
    "                      var_name='year',\n",
    "                      value_name=f'{subject}_score')\n",
    "    \n",
    "    # Limpiamos la columna año\n",
    "    df_long['year'] = df_long['year'].str.extract('(\\d{4})').astype(int)\n",
    "    \n",
    "    return df_long\n",
    "\n",
    "# Aplicamos la transformación a cada materia\n",
    "math_long = reshape_pisa_data(math_df, 'math')\n",
    "reading_long = reshape_pisa_data(reading_df, 'reading')\n",
    "science_long = reshape_pisa_data(science_df, 'science')\n",
    "\n",
    "# Combinamos los datasets\n",
    "pisa_long = math_long.merge(\n",
    "    reading_long[['Country', 'year', 'reading_score']], \n",
    "    on=['Country', 'year']\n",
    ").merge(\n",
    "    science_long[['Country', 'year', 'science_score']], \n",
    "    on=['Country', 'year']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Preparación para el PSM (usando datos de 2018)\n",
    "def prepare_matching_data(df):\n",
    "    # Filtramos datos de 2018\n",
    "    matching_data = df[df['year'] == 2018].copy()\n",
    "    \n",
    "    # Seleccionamos variables para el matching\n",
    "    matching_vars = ['GDP_Per_Capita_2018', 'Education_Spending_Percent_GDP',\n",
    "                    'math_score', 'reading_score', 'science_score']\n",
    "    \n",
    "    # Estandarizamos las variables\n",
    "    scaler = StandardScaler()\n",
    "    matching_data[matching_vars] = scaler.fit_transform(matching_data[matching_vars])\n",
    "    \n",
    "    return matching_data\n",
    "\n",
    "matching_data = prepare_matching_data(pisa_long)\n",
    "\n",
    "# 3. Estimación del Propensity Score\n",
    "def estimate_propensity_score(data):\n",
    "    # Preparamos X y y para la regresión logística\n",
    "    X = data[['GDP_Per_Capita_2018', 'Education_Spending_Percent_GDP',\n",
    "              'math_score', 'reading_score', 'science_score']]\n",
    "    y = data['Treatment']\n",
    "    \n",
    "    # Estimamos el modelo\n",
    "    pscore_model = LogisticRegression(random_state=42)\n",
    "    pscore_model.fit(X, y)\n",
    "    \n",
    "    # Calculamos los propensity scores\n",
    "    pscores = pscore_model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    return pscores\n",
    "\n",
    "matching_data['pscore'] = estimate_propensity_score(matching_data)\n",
    "\n",
    "# 4. Matching\n",
    "def nearest_neighbor_matching(data, n_neighbors=1):\n",
    "    treated = data[data['Treatment'] == 1]\n",
    "    control = data[data['Treatment'] == 0]\n",
    "    \n",
    "    matches = pd.DataFrame()\n",
    "    \n",
    "    for idx, treated_unit in treated.iterrows():\n",
    "        # Calculamos distancias a todas las unidades de control\n",
    "        distances = abs(control['pscore'] - treated_unit['pscore'])\n",
    "        \n",
    "        # Encontramos los n vecinos más cercanos\n",
    "        nearest_neighbors = distances.nsmallest(n_neighbors)\n",
    "        \n",
    "        # Agregamos los matches al DataFrame\n",
    "        for _, control_idx in nearest_neighbors.items():\n",
    "            match_pair = pd.DataFrame({\n",
    "                'treated_country': treated_unit['Country'],\n",
    "                'control_country': control.loc[control_idx, 'Country'],\n",
    "                'treated_pscore': treated_unit['pscore'],\n",
    "                'control_pscore': control.loc[control_idx, 'pscore'],\n",
    "                'distance': distances[control_idx]\n",
    "            }, index=[0])\n",
    "            \n",
    "            matches = pd.concat([matches, match_pair], ignore_index=True)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "matches = nearest_neighbor_matching(matching_data)\n",
    "\n",
    "# 5. Análisis DiD en la muestra pareada\n",
    "def did_analysis(data, matches):\n",
    "    # Creamos indicador de post-tratamiento (2022)\n",
    "    data['Post'] = (data['year'] >= 2022).astype(int)\n",
    "    \n",
    "    # Filtramos solo países pareados\n",
    "    matched_countries = list(matches['treated_country']) + list(matches['control_country'])\n",
    "    matched_data = data[data['Country'].isin(matched_countries)].copy()\n",
    "    \n",
    "    # Realizamos el análisis para cada materia\n",
    "    subjects = ['math_score', 'reading_score', 'science_score']\n",
    "    results = {}\n",
    "    \n",
    "    for subject in subjects:\n",
    "        # Preparamos el modelo\n",
    "        Y = matched_data[subject]\n",
    "        X = pd.get_dummies(matched_data[['Treatment', 'Post', 'year', 'Country']], \n",
    "                          columns=['year', 'Country'])\n",
    "        X['Treatment_Post'] = X['Treatment'] * X['Post']\n",
    "        \n",
    "        # Estimamos el modelo\n",
    "        model = sm.OLS(Y, X)\n",
    "        results[subject] = model.fit(cov_type='cluster', \n",
    "                                   cov_kwds={'groups': matched_data['Country']})\n",
    "    \n",
    "    return results\n",
    "\n",
    "did_results = did_analysis(pisa_long, matches)\n",
    "\n",
    "# 6. Visualización de resultados\n",
    "def plot_trends(data, matches):\n",
    "    # Filtramos países pareados\n",
    "    matched_countries = list(matches['treated_country']) + list(matches['control_country'])\n",
    "    matched_data = data[data['Country'].isin(matched_countries)].copy()\n",
    "    \n",
    "    # Calculamos promedios por grupo y año\n",
    "    grouped_data = matched_data.groupby(['year', 'Treatment'])[\n",
    "        ['math_score', 'reading_score', 'science_score']].mean().reset_index()\n",
    "    \n",
    "    # Creamos el gráfico\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    subjects = ['math_score', 'reading_score', 'science_score']\n",
    "    \n",
    "    for ax, subject in zip(axes, subjects):\n",
    "        sns.lineplot(data=grouped_data, x='year', y=subject, \n",
    "                    hue='Treatment', ax=ax)\n",
    "        ax.axvline(x=2020, color='red', linestyle='--')\n",
    "        ax.set_title(subject.replace('_', ' ').title())\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_trends(pisa_long, matches)\n",
    "\n",
    "# 7. Análisis de robustez\n",
    "def balance_test(data, matches):\n",
    "    # Filtramos países pareados\n",
    "    matched_countries = list(matches['treated_country']) + list(matches['control_country'])\n",
    "    matched_data = data[data['Country'].isin(matched_countries)].copy()\n",
    "    \n",
    "    # Variables para el test de balance\n",
    "    balance_vars = ['GDP_Per_Capita_2018', 'Education_Spending_Percent_GDP',\n",
    "                   'math_score', 'reading_score', 'science_score']\n",
    "    \n",
    "    # Realizamos t-tests\n",
    "    balance_results = pd.DataFrame(columns=['Variable', 'Diff', 'P-value'])\n",
    "    \n",
    "    for var in balance_vars:\n",
    "        t_stat, p_val = stats.ttest_ind(\n",
    "            matched_data[matched_data['Treatment']==1][var],\n",
    "            matched_data[matched_data['Treatment']==0][var]\n",
    "        )\n",
    "        \n",
    "        balance_results = pd.concat([balance_results,\n",
    "            pd.DataFrame({\n",
    "                'Variable': [var],\n",
    "                'Diff': [t_stat],\n",
    "                'P-value': [p_val]\n",
    "            })\n",
    "        ])\n",
    "    \n",
    "    return balance_results\n",
    "\n",
    "balance_results = balance_test(matching_data, matches)\n",
    "\n",
    "# Imprimimos resultados\n",
    "print(\"\\nBalance Test Results:\")\n",
    "print(balance_results)\n",
    "\n",
    "print(\"\\nDiD Results:\")\n",
    "for subject, result in did_results.items():\n",
    "    print(f\"\\n{subject}\")\n",
    "    print(result.summary().tables[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
